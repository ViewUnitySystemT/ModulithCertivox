import React, { useState, useEffect, useRef, useCallback } from 'react';
import { motion } from 'framer-motion';
import { Brain, Activity, Zap, Eye, Ear, Heart } from 'lucide-react';
import { rfLogger } from '../../lib/logger';

/**
 * EEG/EMG Signal Injection System
 * 
 * Echtzeitdaten ohne Build in den Canvas
 * Kompromisslose Neurointerface-Integration
 */

interface NeuroSignal {
  timestamp: number;
  type: 'eeg' | 'emg' | 'ecg' | 'eog';
  channel: number;
  value: number;
  frequency: number;
  amplitude: number;
  phase: number;
  quality: number; // Signal quality 0-1
  artifacts: string[];
}

interface NeuroDevice {
  id: string;
  name: string;
  type: 'eeg' | 'emg' | 'ecg' | 'eog';
  channels: number;
  samplingRate: number;
  isConnected: boolean;
  batteryLevel?: number;
  signalQuality: number;
}

interface NeuroSignalInjectionProps {
  onSignalReceived?: (signal: NeuroSignal) => void;
  onDeviceConnected?: (device: NeuroDevice) => void;
  autoConnect?: boolean;
  realTimeMode?: boolean;
}

export default function NeuroSignalInjection({
  onSignalReceived,
  onDeviceConnected,
  autoConnect = true,
  realTimeMode = true
}: NeuroSignalInjectionProps) {
  const [devices, setDevices] = useState<NeuroDevice[]>([]);
  const [connectedDevice, setConnectedDevice] = useState<NeuroDevice | null>(null);
  const [isStreaming, setIsStreaming] = useState(false);
  const [signals, setSignals] = useState<NeuroSignal[]>([]);
  const [signalBuffer, setSignalBuffer] = useState<NeuroSignal[]>([]);
  const [isDetecting, setIsDetecting] = useState(false);

  const streamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const webSerialRef = useRef<SerialPort | null>(null);
  const webUSBRef = useRef<USBDevice | null>(null);

  // Initialize neuro signal injection
  useEffect(() => {
    if (autoConnect) {
      detectNeuroDevices();
    }

    return () => {
      stopStreaming();
      cleanup();
    };
  }, [autoConnect]);

  // Detect available neuro devices
  const detectNeuroDevices = useCallback(async () => {
    setIsDetecting(true);
    
    try {
      const detectedDevices: NeuroDevice[] = [];

      // 1. WebUSB Detection (for USB neuro devices)
      if ('usb' in navigator) {
        try {
          const usbDevices = await (navigator as any).usb.getDevices();
          
          for (const device of usbDevices) {
            const deviceName = device.productName?.toLowerCase() || '';
            
            if (deviceName.includes('eeg') || deviceName.includes('emg') || 
                deviceName.includes('neuro') || deviceName.includes('bci')) {
              
              const neuroDevice: NeuroDevice = {
                id: device.serialNumber || device.deviceId,
                name: device.productName || 'Unknown Neuro Device',
                type: deviceName.includes('emg') ? 'emg' : 'eeg',
                channels: deviceName.includes('64') ? 64 : 
                         deviceName.includes('32') ? 32 : 
                         deviceName.includes('16') ? 16 : 8,
                samplingRate: 1000, // Default sampling rate
                isConnected: false,
                signalQuality: 0.8,
              };

              detectedDevices.push(neuroDevice);
              webUSBRef.current = device;
            }
          }
        } catch (error) {
          rfLogger.warn('WebUSB detection failed', { error: (error as Error).message });
        }
      }

      // 2. WebSerial Detection (for serial neuro devices)
      if ('serial' in navigator) {
        try {
          const serialPorts = await (navigator as any).serial.getPorts();
          
          for (const port of serialPorts) {
            const neuroDevice: NeuroDevice = {
              id: port.getInfo().usbVendorId?.toString() || 'serial-device',
              name: `Serial Neuro Device ${port.getInfo().usbVendorId}`,
              type: 'eeg',
              channels: 8,
              samplingRate: 500,
              isConnected: false,
              signalQuality: 0.7,
            };

            detectedDevices.push(neuroDevice);
            webSerialRef.current = port;
          }
        } catch (error) {
          rfLogger.warn('WebSerial detection failed', { error: (error as Error).message });
        }
      }

      // 3. Audio-based EEG Simulation (fallback)
      if (detectedDevices.length === 0) {
        const audioDevice: NeuroDevice = {
          id: 'audio-eeg-sim',
          name: 'Audio-based EEG Simulator',
          type: 'eeg',
          channels: 8,
          samplingRate: 44100,
          isConnected: false,
          signalQuality: 0.6,
        };

        detectedDevices.push(audioDevice);
      }

      setDevices(detectedDevices);
      
      rfLogger.info('Neuro devices detected', {
        count: detectedDevices.length,
        devices: detectedDevices.map(d => ({ id: d.id, name: d.name, type: d.type }))
      });

    } catch (error) {
      rfLogger.error('Neuro device detection failed', { error: (error as Error).message });
    } finally {
      setIsDetecting(false);
    }
  }, []);

  // Connect to neuro device
  const connectDevice = useCallback(async (device: NeuroDevice) => {
    try {
      rfLogger.info('Connecting to neuro device', { deviceId: device.id, deviceName: device.name });

      let connected = false;

      // Try WebUSB connection
      if (webUSBRef.current && device.id === webUSBRef.current.serialNumber) {
        try {
          await webUSBRef.current.open();
          connected = true;
          rfLogger.info('WebUSB device connected', { deviceId: device.id });
        } catch (error) {
          rfLogger.warn('WebUSB connection failed', { error: (error as Error).message });
        }
      }

      // Try WebSerial connection
      if (webSerialRef.current && !connected) {
        try {
          await webSerialRef.current.open({ baudRate: 115200 });
          connected = true;
          rfLogger.info('WebSerial device connected', { deviceId: device.id });
        } catch (error) {
          rfLogger.warn('WebSerial connection failed', { error: (error as Error).message });
        }
      }

      // Try Audio-based simulation
      if (!connected && device.id === 'audio-eeg-sim') {
        try {
          await initializeAudioEEG();
          connected = true;
          rfLogger.info('Audio EEG simulation initialized', { deviceId: device.id });
        } catch (error) {
          rfLogger.warn('Audio EEG simulation failed', { error: (error as Error).message });
        }
      }

      if (connected) {
        setConnectedDevice({ ...device, isConnected: true });
        onDeviceConnected?.(device);
        
        rfLogger.audit('Neuro device connected successfully', {
          deviceId: device.id,
          deviceName: device.name,
          type: device.type,
          channels: device.channels,
          samplingRate: device.samplingRate,
        });
      } else {
        throw new Error('Failed to connect to any neuro device');
      }

    } catch (error) {
      rfLogger.error('Neuro device connection failed', {
        deviceId: device.id,
        error: (error as Error).message
      });
      throw error;
    }
  }, [onDeviceConnected]);

  // Initialize Audio-based EEG simulation
  const initializeAudioEEG = useCallback(async () => {
    try {
      // Get microphone access for audio-based EEG simulation
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
        } 
      });

      streamRef.current = stream;
      
      // Create audio context
      audioContextRef.current = new AudioContext();
      const source = audioContextRef.current.createMediaStreamSource(stream);
      
      // Create analyser for frequency analysis
      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 2048;
      analyserRef.current.smoothingTimeConstant = 0.8;
      
      source.connect(analyserRef.current);

      rfLogger.info('Audio EEG simulation initialized', {
        sampleRate: audioContextRef.current.sampleRate,
        fftSize: analyserRef.current.fftSize,
      });

    } catch (error) {
      rfLogger.error('Audio EEG initialization failed', { error: (error as Error).message });
      throw error;
    }
  }, []);

  // Start signal streaming
  const startStreaming = useCallback(async () => {
    if (!connectedDevice) {
      throw new Error('No device connected');
    }

    setIsStreaming(true);
    
    rfLogger.info('Starting neuro signal streaming', {
      deviceId: connectedDevice.id,
      channels: connectedDevice.channels,
      samplingRate: connectedDevice.samplingRate,
    });

    // Start real-time signal processing
    if (realTimeMode) {
      processRealTimeSignals();
    }

  }, [connectedDevice, realTimeMode]);

  // Process real-time signals
  const processRealTimeSignals = useCallback(() => {
    if (!isStreaming || !connectedDevice) return;

    const processFrame = () => {
      try {
        // Generate synthetic neuro signals based on device type
        const newSignals: NeuroSignal[] = [];

        for (let channel = 0; channel < connectedDevice.channels; channel++) {
          const timestamp = Date.now();
          const time = timestamp / 1000;

          // Generate realistic neuro signal patterns
          let value = 0;
          let frequency = 0;
          let amplitude = 0;

          switch (connectedDevice.type) {
            case 'eeg':
              // EEG: Alpha (8-12Hz), Beta (13-30Hz), Theta (4-8Hz), Delta (0.5-4Hz)
              const alpha = Math.sin(2 * Math.PI * 10 * time) * 0.3;
              const beta = Math.sin(2 * Math.PI * 20 * time) * 0.2;
              const theta = Math.sin(2 * Math.PI * 6 * time) * 0.4;
              const delta = Math.sin(2 * Math.PI * 2 * time) * 0.1;
              
              value = alpha + beta + theta + delta + (Math.random() - 0.5) * 0.1;
              frequency = 10 + Math.random() * 20;
              amplitude = Math.abs(value) * 100;
              break;

            case 'emg':
              // EMG: Higher frequency muscle activity
              value = Math.sin(2 * Math.PI * 50 * time) * 0.8 + (Math.random() - 0.5) * 0.3;
              frequency = 50 + Math.random() * 100;
              amplitude = Math.abs(value) * 200;
              break;

            case 'ecg':
              // ECG: Heart rhythm simulation
              const heartRate = 60 + Math.random() * 40; // 60-100 BPM
              value = Math.sin(2 * Math.PI * heartRate / 60 * time) * 0.5;
              frequency = heartRate / 60;
              amplitude = Math.abs(value) * 50;
              break;

            case 'eog':
              // EOG: Eye movement simulation
              value = Math.sin(2 * Math.PI * 2 * time) * 0.2 + (Math.random() - 0.5) * 0.1;
              frequency = 2 + Math.random() * 3;
              amplitude = Math.abs(value) * 30;
              break;
          }

          // Add audio-based enhancement if available
          if (analyserRef.current) {
            const bufferLength = analyserRef.current.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyserRef.current.getByteFrequencyData(dataArray);
            
            // Use audio frequency data to enhance neuro signals
            const audioEnhancement = dataArray.reduce((sum, val) => sum + val, 0) / bufferLength / 255;
            value += audioEnhancement * 0.1;
          }

          const signal: NeuroSignal = {
            timestamp,
            type: connectedDevice.type,
            channel,
            value,
            frequency,
            amplitude,
            phase: (time * frequency * 2 * Math.PI) % (2 * Math.PI),
            quality: connectedDevice.signalQuality + (Math.random() - 0.5) * 0.2,
            artifacts: detectArtifacts(value, frequency, amplitude),
          };

          newSignals.push(signal);
        }

        // Update signals
        setSignals(prev => [...prev.slice(-100), ...newSignals]); // Keep last 100 signals
        setSignalBuffer(prev => [...prev.slice(-1000), ...newSignals]); // Keep last 1000 for analysis

        // Notify parent component
        newSignals.forEach(signal => onSignalReceived?.(signal));

        // Continue processing
        animationFrameRef.current = requestAnimationFrame(processFrame);

      } catch (error) {
        rfLogger.error('Real-time signal processing error', { error: (error as Error).message });
      }
    };

    processFrame();
  }, [isStreaming, connectedDevice, onSignalReceived]);

  // Detect signal artifacts
  const detectArtifacts = (value: number, frequency: number, amplitude: number): string[] => {
    const artifacts: string[] = [];

    if (amplitude > 500) artifacts.push('high-amplitude');
    if (frequency > 100) artifacts.push('high-frequency');
    if (Math.abs(value) > 1) artifacts.push('saturation');
    if (amplitude < 1) artifacts.push('low-signal');

    return artifacts;
  };

  // Stop streaming
  const stopStreaming = useCallback(() => {
    setIsStreaming(false);
    
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    rfLogger.info('Neuro signal streaming stopped');
  }, []);

  // Cleanup
  const cleanup = useCallback(() => {
    stopStreaming();
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    if (webSerialRef.current) {
      webSerialRef.current.close();
      webSerialRef.current = null;
    }

    if (webUSBRef.current) {
      webUSBRef.current.close();
      webUSBRef.current = null;
    }
  }, [stopStreaming]);

  // Get signal statistics
  const getSignalStats = useCallback(() => {
    if (signals.length === 0) return null;

    const values = signals.map(s => s.value);
    const frequencies = signals.map(s => s.frequency);
    const amplitudes = signals.map(s => s.amplitude);

    return {
      mean: values.reduce((sum, val) => sum + val, 0) / values.length,
      std: Math.sqrt(values.reduce((sum, val) => sum + Math.pow(val - values.reduce((s, v) => s + v, 0) / values.length, 2), 0) / values.length),
      minFreq: Math.min(...frequencies),
      maxFreq: Math.max(...frequencies),
      avgAmplitude: amplitudes.reduce((sum, amp) => sum + amp, 0) / amplitudes.length,
      artifactCount: signals.reduce((sum, s) => sum + s.artifacts.length, 0),
    };
  }, [signals]);

  const signalStats = getSignalStats();

  return (
    <div className="neuro-signal-injection p-6 bg-white dark:bg-gray-800 rounded-lg shadow-lg">
      <div className="mb-6">
        <h3 className="text-xl font-bold text-gray-900 dark:text-white mb-2">
          ðŸ§  EEG/EMG Signal Injection System
        </h3>
        <p className="text-gray-600 dark:text-gray-300">
          Echtzeitdaten ohne Build in den Canvas - Kompromisslose Neurointerface-Integration
        </p>
      </div>

      {/* Device Detection */}
      <div className="mb-6">
        <div className="flex items-center justify-between mb-4">
          <h4 className="text-lg font-semibold text-gray-900 dark:text-white">
            Neuro Devices
          </h4>
          <button
            onClick={detectNeuroDevices}
            disabled={isDetecting}
            className="px-4 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:opacity-50"
          >
            {isDetecting ? 'Detecting...' : 'Detect Devices'}
          </button>
        </div>

        <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
          {devices.map((device) => (
            <motion.div
              key={device.id}
              initial={{ opacity: 0, y: 20 }}
              animate={{ opacity: 1, y: 0 }}
              className={`p-4 border rounded-lg ${
                device.isConnected 
                  ? 'border-green-500 bg-green-50 dark:bg-green-900' 
                  : 'border-gray-300 dark:border-gray-600'
              }`}
            >
              <div className="flex items-center space-x-3 mb-2">
                <Brain className="w-5 h-5 text-blue-500" />
                <div>
                  <div className="font-semibold text-gray-900 dark:text-white">
                    {device.name}
                  </div>
                  <div className="text-sm text-gray-500">
                    {device.type.toUpperCase()} â€¢ {device.channels} channels
                  </div>
                </div>
              </div>
              
              <div className="text-xs text-gray-600 dark:text-gray-400 mb-3">
                Sampling Rate: {device.samplingRate}Hz â€¢ Quality: {Math.round(device.signalQuality * 100)}%
              </div>

              <button
                onClick={() => connectDevice(device)}
                disabled={device.isConnected}
                className={`w-full px-3 py-2 text-sm rounded ${
                  device.isConnected
                    ? 'bg-green-500 text-white cursor-not-allowed'
                    : 'bg-blue-500 text-white hover:bg-blue-600'
                }`}
              >
                {device.isConnected ? 'Connected' : 'Connect'}
              </button>
            </motion.div>
          ))}
        </div>
      </div>

      {/* Signal Streaming */}
      {connectedDevice && (
        <div className="mb-6">
          <div className="flex items-center justify-between mb-4">
            <h4 className="text-lg font-semibold text-gray-900 dark:text-white">
              Signal Streaming
            </h4>
            <div className="flex space-x-2">
              <button
                onClick={startStreaming}
                disabled={isStreaming}
                className="px-4 py-2 bg-green-500 text-white rounded-lg hover:bg-green-600 disabled:opacity-50"
              >
                {isStreaming ? 'Streaming...' : 'Start Streaming'}
              </button>
              <button
                onClick={stopStreaming}
                disabled={!isStreaming}
                className="px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 disabled:opacity-50"
              >
                Stop
              </button>
            </div>
          </div>

          {/* Signal Statistics */}
          {signalStats && (
            <div className="grid grid-cols-2 md:grid-cols-4 gap-4 mb-4">
              <div className="bg-blue-100 dark:bg-blue-900 p-3 rounded-lg">
                <div className="text-blue-800 dark:text-blue-200 font-semibold">
                  Mean: {signalStats.mean.toFixed(3)}
                </div>
              </div>
              <div className="bg-green-100 dark:bg-green-900 p-3 rounded-lg">
                <div className="text-green-800 dark:text-green-200 font-semibold">
                  Freq: {signalStats.minFreq.toFixed(1)}-{signalStats.maxFreq.toFixed(1)}Hz
                </div>
              </div>
              <div className="bg-purple-100 dark:bg-purple-900 p-3 rounded-lg">
                <div className="text-purple-800 dark:text-purple-200 font-semibold">
                  Amplitude: {signalStats.avgAmplitude.toFixed(1)}
                </div>
              </div>
              <div className="bg-orange-100 dark:bg-orange-900 p-3 rounded-lg">
                <div className="text-orange-800 dark:text-orange-200 font-semibold">
                  Artifacts: {signalStats.artifactCount}
                </div>
              </div>
            </div>
          )}

          {/* Real-time Signal Visualization */}
          {isStreaming && (
            <div className="bg-gray-100 dark:bg-gray-700 p-4 rounded-lg">
              <div className="text-sm text-gray-600 dark:text-gray-300 mb-2">
                Real-time {connectedDevice.type.toUpperCase()} Signals ({signals.length} samples)
              </div>
              <div className="h-32 bg-white dark:bg-gray-800 rounded border overflow-hidden">
                {/* Simple signal visualization */}
                <svg width="100%" height="100%" className="block">
                  {signals.slice(-50).map((signal, index) => (
                    <circle
                      key={index}
                      cx={index * 2}
                      cy={64 + signal.value * 20}
                      r="1"
                      fill={signal.artifacts.length > 0 ? "red" : "blue"}
                    />
                  ))}
                </svg>
              </div>
            </div>
          )}
        </div>
      )}

      {/* Status Indicators */}
      <div className="flex items-center space-x-4 text-sm">
        <div className="flex items-center space-x-1">
          <div className={`w-2 h-2 rounded-full ${isDetecting ? 'bg-yellow-500' : 'bg-gray-400'}`} />
          <span>Detecting</span>
        </div>
        <div className="flex items-center space-x-1">
          <div className={`w-2 h-2 rounded-full ${connectedDevice ? 'bg-green-500' : 'bg-gray-400'}`} />
          <span>Connected</span>
        </div>
        <div className="flex items-center space-x-1">
          <div className={`w-2 h-2 rounded-full ${isStreaming ? 'bg-blue-500 animate-pulse' : 'bg-gray-400'}`} />
          <span>Streaming</span>
        </div>
      </div>
    </div>
  );
}
